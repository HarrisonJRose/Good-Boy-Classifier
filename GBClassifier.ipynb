{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GBClassifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMcm6TxMzn7y"
      },
      "outputs": [],
      "source": [
        "#Import general libraries\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "#Import ML libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.optimizers as optimizers\n",
        "import tensorflow.keras.datasets as datasets\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Update path folder to local directory\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/Good Boy Classifier\"\n",
        "data_path = path + \"/Data\"\n",
        "#Using reduced classes\n",
        "dog_classes = ['Logan', 'Wills'] #Short for Willoughby \n",
        "validation_classes = ['Logan Validation', 'Wills Validation']"
      ],
      "metadata": {
        "id": "NkW5_dji0Og0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a function to add noise to training images in the generator\n",
        "def addNoise(img):\n",
        "    strength = 10 #Ideal noise strength between 0-20\n",
        "    deviation = strength*random.random()\n",
        "    noise = np.random.normal(0, deviation, img.shape)\n",
        "    img += noise\n",
        "    img = np.clip(img, 0, 255)\n",
        "    return img\n",
        "\n",
        "#Data augmentation for training data\n",
        "#Small dataset so we must use extensive augmentation\n",
        "training_datagen = ImageDataGenerator(\n",
        "    rotation_range = 20,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    brightness_range = [0.8,1.0],\n",
        "    zoom_range = [0.5,1.0],\n",
        "    rescale = 1.0/255, #Images stored as ints so rescale required\n",
        "    preprocessing_function = addNoise\n",
        ")\n",
        "\n",
        "#Data flow for training data\n",
        "training_generator = training_datagen.flow_from_directory(data_path,\n",
        "    target_size = (224,224),\n",
        "    classes=dog_classes,\n",
        "    class_mode='categorical',\n",
        "    interpolation='lanczos', #Improve image quality on downsizing\n",
        "    batch_size=8)#Small batches appear to work better for limited dataset\n",
        "\n",
        "#Data augmentation for validation data\n",
        "#No changes made here beyond converting int to float\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale = 1.0/255,\n",
        ")\n",
        "\n",
        "#Data flow for validation data\n",
        "validation_generator = validation_datagen.flow_from_directory(data_path,\n",
        "                                        target_size = (224,224),\n",
        "                                        classes=validation_classes,\n",
        "                                        class_mode='categorical',\n",
        "                                        interpolation='lanczos', #Improve image quality on downsizing\n",
        "                                        batch_size=16) #Max batch size without clipping 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9bPQyzC0kcz",
        "outputId": "d1f2a31d-cb08-4f30-f05d-37a4d8a93698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generic image grid function for visualisations\n",
        "def plotImageGrid(images, labels, title = '', width = 3):\n",
        "  num_displayed = width**2\n",
        "  if (len(images) >= num_displayed) and (len(labels) >= num_displayed):\n",
        "    for i in range(num_displayed):\n",
        "      plt.subplot(width,width,1+i)\n",
        "      plt.axis('off')\n",
        "      plt.title(labels[i])\n",
        "      plt.imshow(images[i], cmap='gray_r')\n",
        "    plt.subplots_adjust(hspace=1) \n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.88)\n",
        "    plt.show()\n",
        "  else:\n",
        "    raise ValueError(\"Insufficient images or labels for gridsize\")"
      ],
      "metadata": {
        "id": "wryZRiK2112a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample image path for augmentation demonstration:\n",
        "sample_image_location = path + \"/Data/Logan/20150917_113732(0).jpg\"\n",
        "\n",
        "\n",
        "#Visualise 9 augmentations for image at chosen path\n",
        "def visualiseTransformation(image_path):\n",
        "  original_image = tf.keras.preprocessing.image.load_img(image_path)\n",
        "  original_image_array = tf.keras.preprocessing.image.img_to_array(original_image)\n",
        "  print(original_image_array.shape)\n",
        "  print(np.max(original_image_array))\n",
        "  augmented_images = np.zeros((9,512,512,3), dtype='float')\n",
        "  augmented_images_labels = np.zeros((9), dtype='str')\n",
        "  original_image_array_resized = original_image_array/255.\n",
        "  plt.title(\"Original Image\")\n",
        "  plt.axis('off')\n",
        "  plt.imshow(original_image_array_resized)\n",
        "  plt.show()\n",
        "  #Perform augmentations and pass to generic image grid function\n",
        "  for i in range(9):\n",
        "    augmented_images[i] = training_datagen.random_transform(original_image_array)\n",
        "  #Random transform does not perform rescale\n",
        "  augmented_images = augmented_images/255.0\n",
        "  plotImageGrid(augmented_images,augmented_images_labels,\"Augmented Images\",3)"
      ],
      "metadata": {
        "id": "SI4q67wT18NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualise predictions as image grid with labels\n",
        "def visualisePredictions(model):\n",
        "  validation_batch = validation_generator.next()\n",
        "  predictions = model.predict(validation_batch[0])\n",
        "  titles = []\n",
        "  #Define the images and labels, then call generic image grid function\n",
        "  for i in range(len(predictions)):\n",
        "    guess = dog_classes[np.argmax(predictions[i])]\n",
        "    certainty = round(np.max(predictions[i]),2)\n",
        "    answer = dog_classes[np.argmax(validation_batch[1][i])]\n",
        "    titles.append((\"Guess: %s (%s), Answer: %s\" % (guess,certainty,answer)))\n",
        "  print(titles)\n",
        "  plotImageGrid(validation_batch[0],titles,\"PupNet Predictions\",3)"
      ],
      "metadata": {
        "id": "di2q-dJj2GL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualise predictions with breakdown by certainty\n",
        "def analysePrediction(model, num_displayed = 3):\n",
        "  validation_batch = validation_generator.next()\n",
        "  predictions = model.predict(validation_batch[0])\n",
        "  if (len(predictions) >= num_displayed):\n",
        "    for i in range(num_displayed):\n",
        "      #Display Image:\n",
        "      plt.subplot(num_displayed,2,1+i*2)\n",
        "      plt.axis('off')\n",
        "      plt.imshow(validation_batch[0][i], cmap='gray_r')\n",
        "      #Display Predictions:\n",
        "      plt.subplot(num_displayed,2,2+i*2)\n",
        "      plt.barh(dog_classes, predictions[i], align='center', height=0.5)\n",
        "\n",
        "    plt.subplots_adjust(hspace=1) \n",
        "    #plt.suptitle(title)\n",
        "    plt.subplots_adjust(top=0.88)\n",
        "    plt.show()\n",
        "  else:\n",
        "    raise ValueError(\"Insufficient images or labels for gridsize\")"
      ],
      "metadata": {
        "id": "oN9PRuvX2PC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analysePredictionRevised(model, num_displayed = 3):\n",
        "  validation_batch = validation_generator.next()\n",
        "  predictions = model.predict(validation_batch[0])\n",
        "  max_prediction = np.max(predictions[:num_displayed])+0.1\n",
        "  if (len(predictions) >= num_displayed):\n",
        "    fig, axs = plt.subplots(num_displayed, 2,  gridspec_kw={'width_ratios':[1,3]})\n",
        "    for i in range(num_displayed): \n",
        "      axs[i,0].imshow(validation_batch[0][i], cmap='gray_r')\n",
        "      axs[i,0].axis('off')\n",
        "      answer = \"Answer: \" + dog_classes[np.argmax(validation_batch[1][i])]\n",
        "      axs[i,0].set_title(answer)\n",
        "      axs[i,1].barh(dog_classes, predictions[i], align='center', height=0.5)\n",
        "      axs[i,1].set_xlim(0,max_prediction)\n",
        "      axs[i,1].set_title(\"Prediction Confidence\")\n",
        "      \n",
        "  else:\n",
        "    raise ValueError(\"Insufficient images or labels for gridsize\")\n"
      ],
      "metadata": {
        "id": "0QIGQQGiD-Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot training performance\n",
        "def plotTrainingHistory(training_hist,moving_average=20):\n",
        "  epochs = len(training_hist.history['loss'])\n",
        "  x = np.arange(epochs)\n",
        "  loss = training_hist.history['loss']\n",
        "  loss_mv = np.convolve(loss, np.ones(moving_average), 'valid') / moving_average\n",
        "  val_loss = training_hist.history['val_loss']\n",
        "  val_loss_mv = np.convolve(val_loss, np.ones(moving_average), 'valid') / moving_average\n",
        "  print(len(loss_mv))\n",
        "  plt.plot(x,loss,'ob',alpha=0.2)\n",
        "  plt.plot(x[moving_average-1:],loss_mv,'-b')\n",
        "  plt.plot(x,val_loss,'or',alpha=0.2)\n",
        "  plt.plot(x[moving_average-1:],val_loss_mv,'-r')\n",
        "  plt.yscale('log')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend(['Training','Moving Average','Validation','Moving Average'])\n",
        "  plt.show()\n",
        "\n",
        "#plotTrainingHistory(hist)"
      ],
      "metadata": {
        "id": "UGaAEIt-HeCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the base classifier\n",
        "def defineGBClassifier(lr = 5e-4):\n",
        "  #Use resnet 50 body for feature extraction and disable training\n",
        "  feature_extractor = ResNet50(weights='imagenet', \n",
        "                              input_shape=(224, 224, 3),\n",
        "                              include_top=False)\n",
        "  feature_extractor.trainable = False\n",
        "\n",
        "  num_classes = len(dog_classes)\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(feature_extractor)\n",
        "\n",
        "  #Define a simple dense head for dog categorisation\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  #Lr set via experimentation, transfer learning favours lower rate\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=optimizers.Adam(learning_rate=lr),\n",
        "                metrics='accuracy')\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "u5kUIviYA3xs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}